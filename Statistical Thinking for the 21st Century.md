

Version | Date|||
---|---|---|---|
0.01|2019/6/6|效应量||



# 统计学的意义
统计学可以在三个方面为我们提供帮助：
- 描述：用一种大家能理解的简单方式来描述这个复杂的世界。
- 决策：在面对不确定性时，通常需要基于数据做出决策。
- 预测：基于对过去状况的知识对新情况做出预测。

所涉及的基本概念
从数据中学习
聚类Aggregation
采样
因果和统计关系

## 补充材料
### 1. 分类和回归
分类和回归（就是预测），那么我们对于评估指标也从这两个方面分，即回归评估指标和分类评估指标。
#### 1.1 回归评价指标
平均绝对误差

均方误差
```math
MSE = {{1\over{n}} \sum_{i=1}^{n}{(f_i-y_i)^2}}
```
均方根误差
```math
RMSE = \sqrt{MSE}
```
#### 1.2 分类评价指标

- *TP*：将正类预测为正类数
- *FN*：将正类预测为负类数
- *FP*：将负类预测为正类数
- *TN*：将负类预测为负类数

**注**：一般来说，我们将关注的类作为正类。

**准确率（accuracy）**:对于给定的测试数据集，分类器（分类模型）正确分类的样本数与总样本数之比。

**精确率（precision）**:
```math
P = {TP\over{TP+FP}}
```

**召回率（recall）**
```math
R = {TP\over{TP+FN}}
```

**F1值**：是精确率和召回率的调和均值
```math
F_1 = {2TP\over{2TP+FN+FP}}
```

**ROC曲线**

roc曲线是以FDR(FDR=FP/FP+TN)为横轴，以TDR（TDR=TP/(TP+FN)）为纵轴的曲线，如果要理解这个曲线代表的含义，那我们首先必选了解横纵坐标FDR和TDR的含义，FDR代表在所有实际为负类的样本中，被错误地判断为正类的比率，TDR表示在所有实际的正类样本中，被正确的判断为正类的比率，所以说横轴的比值越小越好，纵轴越高越好，那么反应到图上就是曲线与X轴围成的面积越大越好。

# CH 2 Working with data

数据量化表示
- 顺序
- 间隔
- 频率

测量的两个重要性质
- 可靠性
- 可验证性
#### 1.2 如何用样本估计总体
1.选择正确的抽样方法

简单随机抽样
分层抽样
系统抽样
整群抽样
2.用样本均值来估计总体均值

3.用样本标准差来估计总体标准差
## 补充材料 
### 1.如何避免偏见
#### 1.1中心极限定理



#### 1.2 如何用样本估计总体
1. 选择正确的抽样方法
    简单随机抽样
    - 分层抽样
    - 系统抽样
    - 整群抽样
    
2.用样本均值来估计总体均值

3.用样本标准差来估计总体标准差
总体标准差的计算公式为：
```math
\sigma = \sqrt{{1\over{N}} \sum_{i=1}^{n}{(x_i-\mu)^2}}
```
样本标准差的计算公式为：
```math
S=\sqrt{\sum_{i=1}^n{(x_i-\bar{x})} \over{n-1}}
```

4.如何避免偏见
 - 样本偏差：抽样空间中的条目不齐全，因此未包含目标总体中的所有对象，俗称以偏概全。

        避免措施：增大样本数量，样本越大越可靠，基于小样本的结论一般存在以偏概全的问题。
 - 幸存者偏差：根据成功的样本采集数据，但由于其幸存者的概率是极小的，不具有代表性。
 - 
        避免措施：学会多个角度全面观察问题，学会屏蔽噪音。


-   概率偏见：就是人们的心理概率和客观的概率不吻合，而造成的偏差。

        避免措施：学好统计与概率，用数学方法去验证，对于不能验证客观概率的时候，多方面咨询专业人士的看法，降低概率偏见的可能性。


-   信息茧房：指人们的信息领域会习惯性地被自己的兴趣所引导，从而将自己的生活桎梏于像蚕茧一般的“茧房”中的现象。

        避免措施：避免个性化推荐

## 2. 样本置信区间

### 2.1 大样本置信区间（样本容量>= 30）
1.确定要求解的问题

比如我们要用样本均值来估计总体均值。

2.求出样本均值和标准误差

其中标准误差SE = 样本标准差`$s/ \sqrt{n}$` ，n为样本大小。

3.常用的置信水平为95%，根据置信水平，求出z值。
常用的置信水平和对应z值如下：

置信水平 | z
---|---
90% | 1.64
95% | 1.96
99% | 2.58

4.计算置信区间上下限

下限a = 样本均值 – z*标准误差

上限b = 样本均值 + z*标准误差


### 2.2 小样本置信区间(样本容量<30)
1.确定要求解的问题

比如我们要用样本均值来估计总体均值。

2.求出样本均值和标准误差

其中标准误差SE = 样本标准差`$s/ \sqrt{n}$` ，n为样本大小。

3.确定置信水平

因为小样本的抽样分布属于t分布，而非正态分布，所以我们通过查询t表格来确定t值的大小。

t值是根据置信水平和自由度(Fn)共同确定的。其中Fn = n - 1，n表示样本大小。

4.计算置信区间上下限

下限a = 样本均值 – t*标准误差

上限b = 样本均值 + t*标准误差

# CH 3 概率
如何获取概率
- 个人观点
- 经验
- 古典概率

## 3.3概率分布
- 二项分布
- 累积概率分布

## 3.4 条件概率

# CH4 数据总结
## 4.1 频率分布
## 4.2 积分分布

## 补充材料
### 数据异常校验
#### 1.拉依达准则( PauTa Criterion 或 3σ准则) 处理异常数据
这种判别处理原理及方法仅局限于对**正态或近似正态分布**的样本数据处理，它是以测量次数充分大为前提（样本>10），当测量次数少的情形用准则剔除粗大误差是不够可靠的。

**3σ法则**为：
- 数值分布在（μ-σ,μ+σ)中的概率为0.6827
- 数值分布在（μ-2σ,μ+2σ)中的概率为0.9545
- 数值分布在（μ-3σ,μ+3σ)中的概率为0.9973

可以认为，Y 的取值几乎全部集中在（μ-3σ,μ+3σ)区间内，超出这个范围的可能性仅占不到0.3%.

#### 2.
# CH5 模型拟合
## 5.1 统计模型
## 5.2 什么是好的模型
## 最简单的模型-均值模型
### 中值

## z分数
```math
z(x) ={ x-\mu\over{\sigma}}
```

## 补充材料
一个定量变量分析： 
定量分析可以回答什么样的问题。

- 数据是如何分布的?
- 给定数量列的平均值是多少?
- 大多数数据驻留在哪里？
- 数据集中的范围，最小值和最大值是多少？
- 数据集中的异常值是什么？

作为数据统计的术语:

Center, Spread and Shape

**中心**： -数据的中心是什么。我们应该采取什么指标来将其作为中心。测量中心有两种不同的技术。


***平均值***  平均值是所有数据点的平均值，它不稳健，对数据异常值敏感。

***中位数***  中位数是数据点的中心，按升序或降序排序。它很稳健，对异常值不敏感。

**离散度/可变性**： - 数据指向远离中心的距离（可能是平均值或中位数）。

测量稀疏有两种技术。

**标准偏差**
**四分位距（IQR）**

标准偏差是方差的平方根，当数据处于对称分布时将使用它，它将以标准偏差的形式给出距离，如1std，-1std。

IQR是75% - 25%之间的差值，这将给出中间50%的数据距离。它将帮助我们识别中间50%的数据的模式，以及它们与中间值之间的距离。当数据处于非对称分布时，将使用这种方法。

**形状**： - 我们如何知道数据是对称还是非对称分布。形状将为我们提供了解分布类型的信息。如果它是对称的，那么我们将获得钟形曲线，否则其他形状如左偏态或右偏态等。

五个数字汇总统计由列组成min，max，25百分位数（Q1），75百分位数（Q3），50百分位数（Q2）（中位数）。

# CH6 数据可视化

# CH7 取样
## 采样误差
## 平均标准差
## 中心极限定理 The Central Limit Theorem
不严格的通俗解释：样本平均值约等于总体平均值，且不管总体是什么分布，任意一个总这里有两个注意点：
- 不需要总体服从正态分布
- 每一个样本的容量至少得在30个

中心极限定理的存在让我们能够使用样本情况来估计总体情况。体的样本平均值都会围绕在总体的平均值周围，并且呈正态分布。

中心极限定理的作用： 
 - . 估计总体
 - . 根据正态分布的特点来判断某一样本是否属于该总体
  
 
## 置信区间(Confidence intervals)

# CH8 重采样和模拟
## 模特卡罗模拟
## 统计中的随机性

# CH9 假设检验
统计的三个目的
- 描述
- 决定
- 预测
## 9.1 零假设/原假设
零假设的内容一般是希望证明其错误的假设。零假设相对的是对立假设（对立假设，Alternative Hypothesis），即不希望看到的另一种可能。

## 9.3 零假设检验的步骤
1. 做出假设
2. 搜集相关数据
3. 设定原假设和对立假设
4. 对数据进行拟合
5. 计算概率是否满足原假设
6. 判定数据是否具有**显著性**（具有统计学意义）

### 9.3.5 检测数据满足零假设的条件
随机检验(Randomization)


### 补充资料
从T检验、F检验及其统计学意义来讲，主要内容涉及T检验和F检验的由来，T检验和F检验的关系等内容。
#### 1.T检验和F检验的由来
一般而言，为了确定从样本（sample）统计结果推论至总体时所犯错的概率，我们会利用统计学家所开发的一些统计方法，进行统计检定。
通过把所得到的统计检定值，与统计学家建立了一些随机变量的概率分布（probability distribution）进行比较，我们可以知道在多少%的机会下会得到目前的结果。倘若经比较后发现，出现这结果的机率很少，亦即是说，是在机会很少、很罕有的情况下才出现；那我们便可以有信心的说，这不是巧合，是具有统计学上的意义的（用统计学的话讲，就是能够拒绝虚无假设null hypothesis）。相反，若比较后发现，出现的机率很高，并不罕见；那我们便不能很有信心的直指这不是巧合，也许是巧合，也许不是，但我们没能确定。

样本服从正态分布，且样本数量较小(10)，所以这里要用到的统计量为`$t$`统计量，公式如下
```math
t=\frac{\bar{x}-\mu}{S/\sqrt{n}}\sim t(n-1)
```

F值和t值就是这些统计检定值，与它们相对应的概率分布，就是F分布和t分布。统计显著性（sig）就是出现目前样本这结果的机率。
#### 2. 统计学意义（P值或sig值）
结果的统计学意义是结果真实程度（能够代表总体）的一种估计方法。
p值为结果可信程度的一个递减指标，p值越大，我们越不能认为样本中变量的关联是总体中各变量关联的可靠指标。p值是将观察结果认为有效即具有总体代表性的犯错概率。如p=0.05提示样本中变量关联有5%的可能是由于偶然性造成的。即假设总体中任意变量间均无关联，我们重复类似实验，会发现约20个实验中有一个实验，我们所研究的变量关联将等于或强于我们的实验结果。（这并不是说如果变量间存在关联，我们可得到5%或95%次数的相同结果，当总体中的变量存在关联，重复研究和发现关联的可能性与设计的统计学效力有关。）在许多研究领域，0.05的p值通常被认为是可接受错误的边界水平。
#### 3. T检验和F检验
至于具体要检定的内容，须看你是在做哪一个统计程序。
举一个例子，比如，你要检验两独立样本均数差异是否能推论至总体，而行的t检验。
两样本（如某班男生和女生）某变量（如身高）的均数并不相同，但这差别是否能推论至总体，代表总体的情况也是存在着差异呢？
会不会总体中男女生根本没有差别，只不过是你那麼巧抽到这2样本的数值不同？
为此，我们进行t检定，算出一个t检定值。
与统计学家建立的以「总体中没差别」作基础的随机变量t分布进行比较，看看在多少%的机会（亦即显著性sig值）下会得到目前的结果。
若显著性sig值很少，比如<0.05（少于5%机率），亦即是说，「如果」总体「真的」没有差别，那么就只有在机会很少（5%）、很罕有的情况下，才会出现目前这样本的情况。虽然还是有5%机会出错（1-0.05=5%），但我们还是可以「比较有信心」的说：目前样本中这情况（男女生出现差异的情况）不是巧合，是具统计学意义的，「总体中男女生不存差异」的虚无假设应予拒绝，简言之，总体应该存在著差异。
每一种统计方法的检定的内容都不相同，同样是t-检定，可能是上述的检定总体中是否存在差异，也同能是检定总体中的单一值是否等于0或者等于某一个数值。
至于F-检定，方差分析（或译变异数分析，Analysis of Variance），它的原理大致也是上面说的，但它是透过检视变量的方差而进行的。它主要用于：均数差别的显著性检验、分离各有关因素并估计其对总变异的作用、分析因素间的交互作用、方差齐性（Equality of Variances）检验等情况。
#### 4. T检验和F检验关系
t检验过程，是对两样本均数（mean）差别的显著性进行检验。惟t检验须知道两个总体的方差（Variances）是否相等；t检验值的计算会因方差是否相等而有所不同。也就是说，t检验须视乎方差齐性（Equality of Variances）结果。所以，SPSS在进行t-test for Equality of Means的同时，也要做Levene's Test for Equality of Variances 。
##### 4.1在Levene's Test for Equality of Variances一栏中 F值为2.36, Sig.为.128，表示方差齐性检验「没有显著差异」，即两方差齐（Equal Variances），故下面t检验的结果表中要看第一排的数据，亦即方差齐的情况下的t检验的结果。
##### 4.2.在t-test for Equality of Means中，第一排（Variances=Equal）的情况：t=8.892, df=84, 2-Tail Sig=.000, Mean Difference=22.99
既然Sig=.000，亦即，两样本均数差别有显著性意义！
##### 4.3到底看哪个Levene's Test for Equality of Variances一栏中sig,还是看t-test for Equality of Means中那个Sig. （2-tailed）啊?
答案是：两个都要看。先看Levene's Test for Equality of Variances，如果方差齐性检验「没有显著差异」，即两方差齐（Equal Variances），故接著的t检验的结果表中要看第一排的数据，亦即方差齐的情况下的t检验的结果。
反之，如果方差齐性检验「有显著差异」，即两方差不齐（Unequal Variances），故接著的t检验的结果表中要看第二排的数据，亦即方差不齐的情况下的t检验的结果。
##### 4.4你做的是T检验，为什么会有F值呢?
就是因为要评估两个总体的方差（Variances）是否相等，要做Levene's Test for Equality of Variances，要检验方差，故所以就有F值。

另一种解释：
t检验有单样本t检验，配对t检验和两样本t检验。

单样本t检验：是用样本均数代表的未知总体均数和已知总体均数进行比较，来观察此组样本与总体的差异性。

配对t检验：是采用配对设计方法观察以下几种情形，
1，两个同质受试对象分别接受两种不同的处理；
2,同一受试对象接受两种不同的处理；
3，同一受试对象处理前后。

F检验又叫方差齐性检验。在两样本t检验中要用到F检验。
从两研究总体中随机抽取样本，要对这两个样本进行比较的时候，首先要判断两总体方差是否相同，即方差齐性。若两总体方差相等，则直接用t检验，若不等，可采用t检验或变量变换或秩和检验等方法。

其中要判断两总体方差是否相等，就可以用F检验。
若是单组设计，必须给出一个标准值或总体均值，同时，提供一组定量的观测结果，应用t检验的前提条件就是该组资料必须服从正态分布；若是配对设计，每对数据的差值必须服从正态分布；若是成组设计，个体之间相互独立，两组资料均取自正态分布的总体，并满足方差齐性。之所以需要这些前提条件，是因为必须在这样的前提下所计算出的t统计量才服从t分布，而t检验正是以t分布作为其理论依据的检验方法。
简单来说就是实用T检验是有条件的，其中之一就是要符合方差齐次性，这点需要F检验来验证。

#### 5 如何判定结果具有真实的显著性
在最后结论中判断什么样的显著性水平具有统计学意义，不可避免地带有武断性。换句话说，认为结果无效而被拒绝接受的水平的选择具有武断性。实践中，最后的决定通常依赖于数据集比较和分析过程中结果是先验性还是仅仅为均数之间的两两比较，依赖于总体数据集里结论一致的支持性证据的数量，依赖于以往该研究领域的惯例。通常，许多的科学领域中产生p值的结果≤0.05被认为是统计学意义的边界线，但是这显著性水平还包含了相当高的犯错可能性。结果0.05≥p>0.01被认为是具有统计学意义，而0.01≥p≥0.001被认为具有高度统计学意义。但要注意这种分类仅仅是研究基础上非正规的判断常规。

#### 6. 所有的检验统计都是正态分布？
并不完全如此，但大多数检验都直接或间接与之有关，可以从正态分布中推导出来，如t检验、f检验或卡方检验。这些检验一般都要求：所分析变量在总体中呈正态分布，即满足所谓的正态假设。许多观察变量的确是呈正态分布的，这也是正态分布是现实世界的基本特征的原因。当人们用在正态分布基础上建立的检验分析非正态分布变量的数据时问题就产生了，（参阅非参数和方差分析的正态性检验）。这种条件下有两种方法：一是用替代的非参数检验（即无分布性检验），但这种方法不方便，因为从它所提供的结论形式看，这种方法统计效率低下、不灵活。另一种方法是：当确定样本量足够大的情况下，通常还是可以使用基于正态分布前提下的检验。后一种方法是基于一个相当重要的原则产生的，该原则对正态方程基础上的总体检验有极其重要的作用。即，随着样本量的增加，样本分布形状趋于正态，即使所研究的变量分布并不呈正态。

# CH 10 Confidence intervals（置信区间），effect sizes(效应量), and statistical power（统计功效）

## 10.1 置信区间
```math
CI = point setimate \pm critial value
```
### 10.1.1 用正态分布确定置信区间
```math
CI=\bar{X}\pm{1.96*SE}
```
### 10.1.2 基于t分布的置信区间
```math
CI=\bar{X}\pm{t_{crit}*SE}
```

### 10.1.3 样本大小和置信区间

### 10.1.4 
